{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGPIIJlJweUt"
   },
   "source": [
    "# Lab 1 - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GDMQKCJwvIL"
   },
   "source": [
    "## Submission rules\n",
    "\n",
    "1. Lab 1 is an assignment for teams of 2-3 students; the teams are listed on cms. Please make only one submission per team  \n",
    "2. The assignment should be completed in a Google Collaboratory notebook (https://colab.research.google.com/notebooks/intro.ipynb#). To this end, first create a copy of this notebook in your personal Googel Drive via \"File\" --> \"Save a copy in Drive\". Do not forget to    \n",
    " *    rename the notebook and mention all your teammates in the name;      \n",
    " *    share your notebook within ucu.edu.ua domain, so that we will be able to open and grade it :)  \n",
    "3. Submit the link to the final version of the notebook in the comments field of cms and list all the team members therein. No changes may be made to the notebook after the deadline\n",
    "4. At the top of your notebook, provide a work-breakdown structure estimating efforts of each team member.\n",
    "\n",
    "Failure to comply with the submission rules can be a reason of up to 1 point deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1O-SSLytW2k"
   },
   "source": [
    "## Introduction\n",
    "During the past three weeks, you learned a couple of essential notions ant theorems. One of them is Bayes theorem.\n",
    "\n",
    "One of its applications is **Naive Bayes classifier**, which is a probabilistic classifier whose aim is to determine which class some observation probably belongs by using the Bayes formula:\n",
    "$$\\mathsf{P}(\\mathrm{class}\\mid \\mathrm{observation})=\\frac{\\mathsf{P}(\\mathrm{observation}\\mid\\mathrm{class})\\mathsf{P}(\\mathrm{class})}{\\mathsf{P}(\\mathrm{observation})}$$\n",
    "\n",
    "Under the strong independence assumption, one can calculate $\\mathsf{P}(\\mathrm{observation} \\mid \\mathrm{class})$ as\n",
    "$$\\mathsf{P}(\\mathrm{observation}) = \\prod_{i=1}^{n} \\mathsf{P}(\\mathrm{feature}_i),$$\n",
    "where $n$ is the total number of features describing a given observation. Thus, $\\mathsf{P}(\\mathrm{class}|\\mathrm{observation})$ now can be calculated as\n",
    "\n",
    "$$\\mathsf{P}(\\mathrm{class} \\mid \\mathrm{\\mathrm{observation}}) = \\mathsf{P}(\\mathrm{class})\\times \\prod_{i=1}^{n}\\frac{\\mathsf{P}(\\mathrm{feature}_i\\mid \\mathrm{class})}{\\mathsf{P}(\\mathrm{feature}_i)}$$\n",
    "\n",
    "For more detailed explanation, you can check [this link](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzV_ykevv9Tp"
   },
   "source": [
    "## Data  description\n",
    "\n",
    "There are 5 datasets uploaded on the cms. \n",
    "\n",
    "To determine your variant, take your team number from the list of teams on cms and take *mod 5* - this is the number of your data set.\n",
    "\n",
    "* **0 - authors**\n",
    "This data set consists of citations of three famous writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP Lovecraft. The task with this data set is to classify a piece of text with the author who was more likely to write it.\n",
    "\n",
    "* **1 - discrimination**\n",
    "This data set consists of tweets that have discriminatory (sexism or racism) messages or of tweets that are of neutral mood. The task is to determine whether a given tweet has discriminatory mood or does not.\n",
    "\n",
    "* **2 - fake news**\n",
    "This data set contains data of American news: a headline and an abstract of the article.\n",
    "Each piece of news is classified as fake or credible. The task is to classify the news from test.csv as credible or fake.\n",
    "\n",
    "* **3 - sentiment**\n",
    "All the text messages contained in this data set are labeled with three sentiments: positive, neutral or negative. The task is to classify some text message as the one of positive mood, negative or neutral.\n",
    "\n",
    "* **4 - spam**\n",
    "This last data set contains SMS messages classified as spam or non-spam (ham in the data set). The task is to determine whether a given message is spam or non-spam.\n",
    "\n",
    "Each data set consists of two files: *train.csv* and *test.csv*. The first one you will need find the probabilities distributions for each of the features, while the second one is needed for checking how well your classifier works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASP_dWuj9t0l"
   },
   "source": [
    "##Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cv-5_R7D6bTP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/elem/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from functools import lru_cache\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvZsfHRL6JOA"
   },
   "source": [
    "### Data pre-processing\n",
    "* Read the *.csv* data files with *pandas* package. This package will also provide you with a nice interface for data processing even within the classifier implementation.\n",
    "* Сlear your data from punctuation or other unneeded symbols.\n",
    "* Clear you data from stop words. You don’t want words as is, and, or etc. to affect your probabilities distributions, so it is a wise decision to get rid of them. Find list of stop words in the cms under the lab task.\n",
    "* Represent each test message as its bag-of-words. [Here](https://machinelearningmastery.com/gentle-introduction-bag-words-model/) you can find general introduction to the bag-of-words model and examples on to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XeSKb6pQ9DoL"
   },
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def get_stop_words(words_file_path= \"stop_words.txt\") -> set:\n",
    "    \"\"\"\n",
    "    Returns set of words to ignore\n",
    "    \"\"\"\n",
    "    stop_words = set()\n",
    "    with open(words_file_path) as f:\n",
    "        for line in f:\n",
    "            stop_words.add(line.strip())\n",
    "    return stop_words\n",
    "\n",
    "def check_if_word_is_allowed(word: str) -> bool:\n",
    "    return  word.isalnum() and word not in get_stop_words()\n",
    "\n",
    "def normalize_word(word:str) -> str:\n",
    "    return word.lower()\n",
    "\n",
    "def get_bag_of_words(sentence: str) -> str:\n",
    "\n",
    "    # tokenize sentence\n",
    "    # skip words that are in stop_words\n",
    "    # skip words that have digits and punctuation\n",
    "    # lower the words\n",
    "        \n",
    "    bag_of_words = [normalize_word(word) for word in nltk.word_tokenize(sentence) if check_if_word_is_allowed(word)]\n",
    "    return bag_of_words\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_file):\n",
    "    \"\"\"\n",
    "    Function for data processing and split it into X and y sets.\n",
    "    :param data_file: str - train datado a research of your own\n",
    "    :return: pd.Series|list, pd.Series|list - X and y data series or lists\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_file)\n",
    "    total_bag_of_words = [get_bag_of_words(row[\"text\"]) for _, row in df.iterrows()]\n",
    "\n",
    "    return total_bag_of_words, df[\"sentiment\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ntmhf9VA9u0d"
   },
   "source": [
    "*   If you need to implement some additional methods, feel free to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95OjORbi9zAW"
   },
   "source": [
    "### Implementation\n",
    "Implement each method of the BayesianClassifier \n",
    "created according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "rx2-IVxy-R99"
   },
   "outputs": [],
   "source": [
    "class BayesianClassifier:\n",
    "    \"\"\"\n",
    "    Implementation of Naive Bayes classification algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model: pd.DataFrame = None\n",
    "        self.lbl_properties: pd.DataFrame = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit Naive Bayes parameters according to train data X and y.\n",
    "        :param X: pd.DataFrame|list - train input/messages\n",
    "        :param y: pd.DataFrame|list - train output/labels\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        words_counter = defaultdict(lambda: Counter())\n",
    "        for word_list, sentiment in zip(X, y):\n",
    "            for word in word_list:\n",
    "                words_counter[sentiment][word] += 1\n",
    "\n",
    "        words_df = pd.DataFrame(words_counter)\n",
    "        words_df.fillna(0,inplace=True) # replace NaN with 0\n",
    "        words_df[\"word\"] = words_df.index\n",
    "        \n",
    "        labels_df = pd.DataFrame(Counter(y).items(),columns=[\"label\", \"count\"])\n",
    "        labels_df[\"total\"] = len(y)\n",
    "\n",
    "        \n",
    "        self.model = words_df\n",
    "        self.lbl_properties = labels_df\n",
    "\n",
    "    def predict_prob(self, message, label):\n",
    "        \"\"\"\n",
    "        Calculate the probability that a given label can be assigned to a given message.\n",
    "        :param message: str - input message\n",
    "        :param label: str - label\n",
    "        :return: float - probability P(label|message)\n",
    "        \"\"\"\n",
    "        message_probability = 1\n",
    "        word_in_message_counter = Counter(message)\n",
    "        for word in message:\n",
    "            word_row = self.model.loc[self.model['word'] == word]\n",
    "            if word_row.empty:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            label_count = self.lbl_properties.loc[self.lbl_properties[\"label\"] == label][\"count\"].iloc[0]\n",
    "            total_label_count = self.lbl_properties[\"total\"].iloc[0]\n",
    "            \n",
    "            smoothed_word_with_label_count = (word_row[label].iloc[0] + 1)\n",
    "            smoothed_label_count =  label_count + total_label_count\n",
    "            \n",
    "            word_probability_given_label =  smoothed_word_with_label_count / smoothed_label_count\n",
    "            \n",
    "            label_probability = label_count / total_label_count\n",
    "            message_probability *= pow(word_probability_given_label, word_in_message_counter[word]) * label_probability\n",
    "\n",
    "        return message_probability\n",
    "        \n",
    "\n",
    "    def predict(self, message):\n",
    "        \"\"\"\n",
    "        Predict label for a given message.\n",
    "        :param message: str - message\n",
    "        :return: str - label that is most likely to be truly assigned to a given message\n",
    "        \"\"\"\n",
    "        every_label_probability = Counter()\n",
    "        for _,lbl in self.lbl_properties.iterrows():\n",
    "            lbl_name = lbl[\"label\"]\n",
    "            every_label_probability[lbl_name] = self.predict_prob(message, lbl_name)\n",
    "        return every_label_probability.most_common()[0][0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the mean accuracy on the given test data and labels - the efficiency of a trained model.\n",
    "        :param X: pd.DataFrame|list - test data - messages\n",
    "        :param y: pd.DataFrame|list - test labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        correctly_guessed = 0\n",
    "        total_tries = len(X)\n",
    "        for text_list,correct_label in tqdm(zip(X,y)):\n",
    "            predict = self.predict(text_list)\n",
    "            if predict == correct_label:\n",
    "                correctly_guessed += 1\n",
    "        return correctly_guessed / total_tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW85An5p-sp3"
   },
   "source": [
    "\n",
    "### Testing\n",
    "*  Finally, after you are done with your classifier, test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = process_data(\"train.csv\")\n",
    "test_X, test_y = process_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "zo4TZVh4950E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [01:01, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score:  0.36104783599088835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier = BayesianClassifier()\n",
    "classifier.fit(train_X, train_y)\n",
    "classifier.predict_prob(test_X[0], test_y[0])\n",
    "\n",
    "print(\"model score: \", classifier.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkNytMyM-8n0"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Summarize your work by explaining in a few sentences the points listed below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpEbPLoyBTBA"
   },
   "source": [
    "* ### Describe the method implemented in general:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAivLQzK_Ksa"
   },
   "source": [
    "* ### List pros and cons of the method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW1pCL-ZBfUD"
   },
   "source": [
    "* ### Add a few sencences about your implementation of the classifier:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlIcMe8uBz-2"
   },
   "source": [
    "* ### Describe your results:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PS_Lab1_Template.ipynb",
   "provenance": [
    {
     "file_id": "1Av8y_HRDH36u-pA1zwEWZL9n8GdFvlrF",
     "timestamp": 1633697130382
    },
    {
     "file_id": "1aT_CtpODWI7otU6vibcvSxhQp3mXEaP3",
     "timestamp": 1633642142132
    }
   ]
  },
  "kernelspec": {
   "display_name": "PyCharm (lab1)",
   "language": "python",
   "name": "pycharm-62921896"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}