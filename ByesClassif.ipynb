{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGPIIJlJweUt"
   },
   "source": [
    "# Lab 1 - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GDMQKCJwvIL"
   },
   "source": [
    "## Submission rules\n",
    "\n",
    "1. Lab 1 is an assignment for teams of 2-3 students; the teams are listed on cms. Please make only one submission per team  \n",
    "2. The assignment should be completed in a Google Collaboratory notebook (https://colab.research.google.com/notebooks/intro.ipynb#). To this end, first create a copy of this notebook in your personal Googel Drive via \"File\" --> \"Save a copy in Drive\". Do not forget to    \n",
    " *    rename the notebook and mention all your teammates in the name;      \n",
    " *    share your notebook within ucu.edu.ua domain, so that we will be able to open and grade it :)  \n",
    "3. Submit the link to the final version of the notebook in the comments field of cms and list all the team members therein. No changes may be made to the notebook after the deadline\n",
    "4. At the top of your notebook, provide a work-breakdown structure estimating efforts of each team member.\n",
    "\n",
    "Failure to comply with the submission rules can be a reason of up to 1 point deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1O-SSLytW2k"
   },
   "source": [
    "## Introduction\n",
    "During the past three weeks, you learned a couple of essential notions ant theorems. One of them is Bayes theorem.\n",
    "\n",
    "One of its applications is **Naive Bayes classifier**, which is a probabilistic classifier whose aim is to determine which class some observation probably belongs by using the Bayes formula:\n",
    "$$\\mathsf{P}(\\mathrm{class}\\mid \\mathrm{observation})=\\frac{\\mathsf{P}(\\mathrm{observation}\\mid\\mathrm{class})\\mathsf{P}(\\mathrm{class})}{\\mathsf{P}(\\mathrm{observation})}$$\n",
    "\n",
    "Under the strong independence assumption, one can calculate $\\mathsf{P}(\\mathrm{observation} \\mid \\mathrm{class})$ as\n",
    "$$\\mathsf{P}(\\mathrm{observation}) = \\prod_{i=1}^{n} \\mathsf{P}(\\mathrm{feature}_i),$$\n",
    "where $n$ is the total number of features describing a given observation. Thus, $\\mathsf{P}(\\mathrm{class}|\\mathrm{observation})$ now can be calculated as\n",
    "\n",
    "$$\\mathsf{P}(\\mathrm{class} \\mid \\mathrm{\\mathrm{observation}}) = \\mathsf{P}(\\mathrm{class})\\times \\prod_{i=1}^{n}\\frac{\\mathsf{P}(\\mathrm{feature}_i\\mid \\mathrm{class})}{\\mathsf{P}(\\mathrm{feature}_i)}$$\n",
    "\n",
    "For more detailed explanation, you can check [this link](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzV_ykevv9Tp"
   },
   "source": [
    "## Data  description\n",
    "\n",
    "There are 5 datasets uploaded on the cms. \n",
    "\n",
    "To determine your variant, take your team number from the list of teams on cms and take *mod 5* - this is the number of your data set.\n",
    "\n",
    "* **0 - authors**\n",
    "This data set consists of citations of three famous writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP Lovecraft. The task with this data set is to classify a piece of text with the author who was more likely to write it.\n",
    "\n",
    "* **1 - discrimination**\n",
    "This data set consists of tweets that have discriminatory (sexism or racism) messages or of tweets that are of neutral mood. The task is to determine whether a given tweet has discriminatory mood or does not.\n",
    "\n",
    "* **2 - fake news**\n",
    "This data set contains data of American news: a headline and an abstract of the article.\n",
    "Each piece of news is classified as fake or credible. The task is to classify the news from test.csv as credible or fake.\n",
    "\n",
    "* **3 - sentiment**\n",
    "All the text messages contained in this data set are labeled with three sentiments: positive, neutral or negative. The task is to classify some text message as the one of positive mood, negative or neutral.\n",
    "\n",
    "* **4 - spam**\n",
    "This last data set contains SMS messages classified as spam or non-spam (ham in the data set). The task is to determine whether a given message is spam or non-spam.\n",
    "\n",
    "Each data set consists of two files: *train.csv* and *test.csv*. The first one you will need find the probabilities distributions for each of the features, while the second one is needed for checking how well your classifier works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASP_dWuj9t0l"
   },
   "source": [
    "##Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Cv-5_R7D6bTP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2567\n",
       "positive    1286\n",
       "negative     115\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvZsfHRL6JOA"
   },
   "source": [
    "### Data pre-processing\n",
    "* Read the *.csv* data files with *pandas* package. This package will also provide you with a nice interface for data processing even within the classifier implementation.\n",
    "* Сlear your data from punctuation or other unneeded symbols.\n",
    "* Clear you data from stop words. You don’t want words as is, and, or etc. to affect your probabilities distributions, so it is a wise decision to get rid of them. Find list of stop words in the cms under the lab task.\n",
    "* Represent each test message as its bag-of-words. [Here](https://machinelearningmastery.com/gentle-introduction-bag-words-model/) you can find general introduction to the bag-of-words model and examples on to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "XeSKb6pQ9DoL"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def get_stop_words() -> set:\n",
    "    \"\"\"\n",
    "    Returns set of words to ignore\n",
    "    \"\"\"\n",
    "    words_file_path = \"stop_words.txt\"\n",
    "    stop_words = set()\n",
    "    with open(words_file_path) as f:\n",
    "        for line in f:\n",
    "            stop_words.add(line.strip())\n",
    "    return stop_words\n",
    "\n",
    "def prepare_sentence(sentence: str) -> str:\n",
    "    sentence = str(sentence).lower()\n",
    "    \n",
    "    for char in punctuation:\n",
    "        sentence = sentence.replace(char, \"\")\n",
    "        \n",
    "    words = sentence.split()\n",
    "    stop_words = get_stop_words()\n",
    "    counter = Counter()\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            stem = ps.stem(word)\n",
    "            counter[stem] += 1\n",
    "            \n",
    "    return counter\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_file):\n",
    "    \"\"\"\n",
    "    Function for data processing and split it into X and y sets.\n",
    "    :param data_file: str - train datado a research of your own\n",
    "    :return: pd.Series|list, pd.Series|list - X and y data series or lists\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_file)\n",
    "    total_bag_of_words = defaultdict(lambda: Counter())\n",
    "    for idx, row in df.iterrows():\n",
    "        sentiment, text = row[\"sentiment\"], row[\"text\"]\n",
    "        bag_of_words = prepare_sentence(text)\n",
    "        for word, word_count in bag_of_words.items():\n",
    "            total_bag_of_words[sentiment][word] += word_count\n",
    "            \n",
    "            \n",
    "\n",
    "    words_df = pd.DataFrame(total_bag_of_words)\n",
    "    words_df.fillna(0,inplace=True) # replace NaN with 0\n",
    "    words_df[\"total\"] =  words_df[\"neutral\"] + words_df[\"negative\"] + words_df[\"positive\"]\n",
    "#     words_df = words_df.replace(0,1) # smoothing\n",
    "    \n",
    "    label_list = []\n",
    "    for col in [\"neutral\",\"positive\", \"negative\"]:\n",
    "        words_df[f\"{col}_prob\"] = (words_df[col] + 1)/ words_df[\"total\"]\n",
    "        label_list.append([col,words_df[words_df[col] != 0][col].count() / words_df[col].count()])\n",
    "    label_df = pd.DataFrame(label_list,columns=[\"label\",\"prob\"])\n",
    "    return words_df, label_df\n",
    "    \n",
    "x, y = process_data(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words_count = dict()\n",
    "# quantity = 0\n",
    "\n",
    "# for counter in result[0]:\n",
    "#     for element in counter:\n",
    "#         quantity += counter[element]\n",
    "#         all_words_count[element] = {\"positive\":0,\"neutral\":0,\"negative\":0}\n",
    "\n",
    "\n",
    "# for i in range(len(result[1])):\n",
    "#     sentiment =  result[1][i]\n",
    "#     for word in result[0][i]:\n",
    "#         all_words_count[word][sentiment]+=1\n",
    "        \n",
    "# display(all_words_count)\n",
    "        \n",
    "# all_words_prob = dict()\n",
    "# sentiments = [\"positive\",\"neutral\",\"negative\"]\n",
    "# # display(all_words_count)\n",
    "# for word in all_words_count:\n",
    "#     word_dict = all_words_count[word]\n",
    "#     num_of_occurance = word_dict[\"positive\"]+ word_dict[\"neutral\"]+ word_dict[\"negative\"]\n",
    "#     for sentiment in sentiments:\n",
    "#         word_dict[sentiment] = word_dict[sentiment] / num_of_occurance\n",
    "#     word_dict[\"total\"] = num_of_occurance / quantity\n",
    "# # all_words_count\n",
    "# # find P( positive |word) = \n",
    "# # find P( neutral |word) = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ntmhf9VA9u0d"
   },
   "source": [
    "*   If you need to implement some additional methods, feel free to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31634  - symbol values [\".\", \",\", \"(\", \")\", \":\", \"&\",\"-\", \"\\\"\",\"[\",\"]\", \"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30458 - replacing all punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23106 - using stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95OjORbi9zAW"
   },
   "source": [
    "### Implementation\n",
    "Implement each method of the BayesianClassifier \n",
    "created according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "rx2-IVxy-R99"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'word'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2890\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2891\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2892\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'word'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-148-b361fbed37e7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 95\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCounter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'difficult'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'football'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'chicccken'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Alps'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCounter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'play'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'chicccken'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Alps'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-148-b361fbed37e7>\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mprobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mlbl\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlbls\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m             \u001B[0mprobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlbl\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_prob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlbl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m         \u001B[0mprobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprobs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0mprobs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreverse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-148-b361fbed37e7>\u001B[0m in \u001B[0;36mpredict_prob\u001B[0;34m(self, message, label)\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mmultiplication\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m             \u001B[0mword_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'word'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword_info\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m                 \u001B[0mword_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mword_info\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2900\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2901\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2902\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2903\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2904\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2891\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2892\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2893\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2894\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2895\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'word'"
     ]
    }
   ],
   "source": [
    "class BayesianClassifier:\n",
    "    \"\"\"\n",
    "    Implementation of Naive Bayes classification algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model: pd.DataFrame = None\n",
    "        self.lbl_properties: pd.DataFrame = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit Naive Bayes parameters according to train data X and y.\n",
    "        :param X: pd.DataFrame|list - train input/messages\n",
    "        :param y: pd.DataFrame|list - train output/labels\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # P()\n",
    "#         record = {'word': ['difficult', 'exercise', 'play', 'football'],\n",
    "#                    'positive': [0.09, 0.3, 0.12, 0.9],\n",
    "#                    'neutral': [0.2, 0.5, 0.01, 0.3],\n",
    "#                    'negative': [0.2, 0.5, 0.01, 0.15],\n",
    "#                    'total': [0.25, 0.25, 0.25, 0.25]}\n",
    "        \n",
    "#         lbl_properties = {'label': ['positive', 'neutral', 'negative'],\n",
    "#                           'prob': [0.2, 0.3, 0.7]}\n",
    "        \n",
    "        self.model = X\n",
    "        self.lbl_properties = y\n",
    "\n",
    "    def predict_prob(self, message, label):\n",
    "        \"\"\"\n",
    "        Calculate the probability that a given label can be assigned to a given message.\n",
    "        :param message: str - input message\n",
    "        :param label: str - label\n",
    "        :return: float - probability P(label|message)\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        lbl_props = self.lbl_properties\n",
    "        \n",
    "        multiplication = 1\n",
    "        for word, count in message.items():\n",
    "            word_info = model.loc[model['word'] == word]\n",
    "            if len(word_info) != 0:\n",
    "                word_info = word_info.iloc[0]\n",
    "                word_cond = word_info[label]\n",
    "                word_tot = word_info['total']\n",
    "            else:\n",
    "                word_cond = (0 + 1) / (lbl_props[lbl_props['label'] == label].iloc[0]['words_count'] + lbl_props[lbl_props['label'] == 'total'].iloc[0]['words_count'])\n",
    "                word_tot = 1 / lbl_props[lbl_props['label'] == 'total'].iloc[0]['words_count']\n",
    "            multiplication *= (word_cond / word_tot) ** count\n",
    "        \n",
    "        prob = lbl_props[lbl_props['label'] == label].iloc[0]['prob'] * multiplication\n",
    "        \n",
    "        return prob\n",
    "        \n",
    "\n",
    "    def predict(self, message):\n",
    "        \"\"\"\n",
    "        Predict label for a given message.\n",
    "        :param message: str - message\n",
    "        :return: str - label that is most likely to be truly assigned to a given message\n",
    "        \"\"\"\n",
    "        lbl_props = self.lbl_properties\n",
    "        lbls = lbl_props[lbl_props['label'] != 'total']['label']\n",
    "        \n",
    "        probs = {}\n",
    "        for lbl in lbls:\n",
    "            probs[lbl] = self.predict_prob(message, lbl)\n",
    "        probs = list(probs.items())\n",
    "        probs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "        return probs[0][0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the mean accuracy on the given test data and labels - the efficiency of a trained model.\n",
    "        :param X: pd.DataFrame|list - test data - messages\n",
    "        :param y: pd.DataFrame|list - test labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        cor_mes = 0\n",
    "        all_mes = len(X.index)\n",
    "        for idx, message in X.items():\n",
    "            pred = self.predict(message)\n",
    "            real = y.at[idx]\n",
    "            if pred == real:\n",
    "                cor_mes += 1\n",
    "\n",
    "        return cor_mes / all_mes\n",
    "\n",
    "# test\n",
    "    \n",
    "classifier = BayesianClassifier()\n",
    "\n",
    "classifier.fit(x, y)\n",
    "print(classifier.predict(Counter({'difficult': 1, 'football': 1, 'chicccken': 1, 'Alps': 3})))\n",
    "print(classifier.predict(Counter({'play': 1, 'chicccken': 1, 'Alps': 3})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW85An5p-sp3"
   },
   "source": [
    "### Testing\n",
    "*  Finally, after you are done with your classifier, test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zo4TZVh4950E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = None, None\n",
    "# test_X, test_y = process_data(\"your test data file\")\n",
    "\n",
    "classifier = BayesianClassifier()\n",
    "classifier.fit(train_X, train_y)\n",
    "# classifier.predict_prob(Counter({'play': 1, 'football': 1, 'chicccken': 1}), 'positive')\n",
    "classifier.predict(Counter({'difficult': 1, 'football': 1, 'chicccken': 1, 'Alps': 3}))\n",
    "\n",
    "# print(\"model score: \", classifier.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkNytMyM-8n0"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Summarize your work by explaining in a few sentences the points listed below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpEbPLoyBTBA"
   },
   "source": [
    "* ### Describe the method implemented in general:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAivLQzK_Ksa"
   },
   "source": [
    "* ### List pros and cons of the method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW1pCL-ZBfUD"
   },
   "source": [
    "* ### Add a few sencences about your implementation of the classifier:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlIcMe8uBz-2"
   },
   "source": [
    "* ### Describe your results:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PS_Lab1_Template.ipynb",
   "provenance": [
    {
     "file_id": "1Av8y_HRDH36u-pA1zwEWZL9n8GdFvlrF",
     "timestamp": 1633697130382
    },
    {
     "file_id": "1aT_CtpODWI7otU6vibcvSxhQp3mXEaP3",
     "timestamp": 1633642142132
    }
   ]
  },
  "kernelspec": {
   "display_name": "PyCharm (lab1)",
   "language": "python",
   "name": "pycharm-62921896"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}