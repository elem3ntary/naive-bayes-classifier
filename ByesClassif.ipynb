{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGPIIJlJweUt"
   },
   "source": [
    "# Lab 1 - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GDMQKCJwvIL"
   },
   "source": [
    "## Submission rules\n",
    "\n",
    "1. Lab 1 is an assignment for teams of 2-3 students; the teams are listed on cms. Please make only one submission per team  \n",
    "2. The assignment should be completed in a Google Collaboratory notebook (https://colab.research.google.com/notebooks/intro.ipynb#). To this end, first create a copy of this notebook in your personal Googel Drive via \"File\" --> \"Save a copy in Drive\". Do not forget to    \n",
    " *    rename the notebook and mention all your teammates in the name;      \n",
    " *    share your notebook within ucu.edu.ua domain, so that we will be able to open and grade it :)  \n",
    "3. Submit the link to the final version of the notebook in the comments field of cms and list all the team members therein. No changes may be made to the notebook after the deadline\n",
    "4. At the top of your notebook, provide a work-breakdown structure estimating efforts of each team member.\n",
    "\n",
    "Failure to comply with the submission rules can be a reason of up to 1 point deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1O-SSLytW2k"
   },
   "source": [
    "## Introduction\n",
    "During the past three weeks, you learned a couple of essential notions ant theorems. One of them is Bayes theorem.\n",
    "\n",
    "One of its applications is **Naive Bayes classifier**, which is a probabilistic classifier whose aim is to determine which class some observation probably belongs by using the Bayes formula:\n",
    "$$\\mathsf{P}(\\mathrm{class}\\mid \\mathrm{observation})=\\frac{\\mathsf{P}(\\mathrm{observation}\\mid\\mathrm{class})\\mathsf{P}(\\mathrm{class})}{\\mathsf{P}(\\mathrm{observation})}$$\n",
    "\n",
    "Under the strong independence assumption, one can calculate $\\mathsf{P}(\\mathrm{observation} \\mid \\mathrm{class})$ as\n",
    "$$\\mathsf{P}(\\mathrm{observation}) = \\prod_{i=1}^{n} \\mathsf{P}(\\mathrm{feature}_i),$$\n",
    "where $n$ is the total number of features describing a given observation. Thus, $\\mathsf{P}(\\mathrm{class}|\\mathrm{observation})$ now can be calculated as\n",
    "\n",
    "$$\\mathsf{P}(\\mathrm{class} \\mid \\mathrm{\\mathrm{observation}}) = \\mathsf{P}(\\mathrm{class})\\times \\prod_{i=1}^{n}\\frac{\\mathsf{P}(\\mathrm{feature}_i\\mid \\mathrm{class})}{\\mathsf{P}(\\mathrm{feature}_i)}$$\n",
    "\n",
    "For more detailed explanation, you can check [this link](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzV_ykevv9Tp"
   },
   "source": [
    "## Data  description\n",
    "\n",
    "There are 5 datasets uploaded on the cms. \n",
    "\n",
    "To determine your variant, take your team number from the list of teams on cms and take *mod 5* - this is the number of your data set.\n",
    "\n",
    "* **0 - authors**\n",
    "This data set consists of citations of three famous writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP Lovecraft. The task with this data set is to classify a piece of text with the author who was more likely to write it.\n",
    "\n",
    "* **1 - discrimination**\n",
    "This data set consists of tweets that have discriminatory (sexism or racism) messages or of tweets that are of neutral mood. The task is to determine whether a given tweet has discriminatory mood or does not.\n",
    "\n",
    "* **2 - fake news**\n",
    "This data set contains data of American news: a headline and an abstract of the article.\n",
    "Each piece of news is classified as fake or credible. The task is to classify the news from test.csv as credible or fake.\n",
    "\n",
    "* **3 - sentiment**\n",
    "All the text messages contained in this data set are labeled with three sentiments: positive, neutral or negative. The task is to classify some text message as the one of positive mood, negative or neutral.\n",
    "\n",
    "* **4 - spam**\n",
    "This last data set contains SMS messages classified as spam or non-spam (ham in the data set). The task is to determine whether a given message is spam or non-spam.\n",
    "\n",
    "Each data set consists of two files: *train.csv* and *test.csv*. The first one you will need find the probabilities distributions for each of the features, while the second one is needed for checking how well your classifier works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASP_dWuj9t0l"
   },
   "source": [
    "##Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "Cv-5_R7D6bTP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "df = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvZsfHRL6JOA"
   },
   "source": [
    "### Data pre-processing\n",
    "* Read the *.csv* data files with *pandas* package. This package will also provide you with a nice interface for data processing even within the classifier implementation.\n",
    "* Сlear your data from punctuation or other unneeded symbols.\n",
    "* Clear you data from stop words. You don’t want words as is, and, or etc. to affect your probabilities distributions, so it is a wise decision to get rid of them. Find list of stop words in the cms under the lab task.\n",
    "* Represent each test message as its bag-of-words. [Here](https://machinelearningmastery.com/gentle-introduction-bag-words-model/) you can find general introduction to the bag-of-words model and examples on to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "XeSKb6pQ9DoL"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def get_stop_words() -> set:\n",
    "    \"\"\"\n",
    "    Returns set of words to ignore\n",
    "    \"\"\"\n",
    "    words_file_path = \"stop_words.txt\"\n",
    "    stop_words = set()\n",
    "    with open(words_file_path) as f:\n",
    "        for line in f:\n",
    "            stop_words.add(line.strip())\n",
    "    return stop_words\n",
    "\n",
    "def prepare_sentence(sentence: str) -> str:\n",
    "    sentence = str(sentence).lower()\n",
    "    \n",
    "    for char in punctuation:\n",
    "        sentence = sentence.replace(char, \"\")\n",
    "        \n",
    "    words = sentence.split()\n",
    "    stop_words = get_stop_words()\n",
    "    counter = Counter()\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            stem = ps.stem(word)\n",
    "            counter[stem] += 1\n",
    "            \n",
    "    return counter\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        neutral\n",
       "1        neutral\n",
       "2       negative\n",
       "3       positive\n",
       "4       positive\n",
       "          ...   \n",
       "3963     neutral\n",
       "3964     neutral\n",
       "3965     neutral\n",
       "3966     neutral\n",
       "3967     neutral\n",
       "Name: sentiment, Length: 3968, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_data(data_file):\n",
    "    \"\"\"\n",
    "    Function for data processing and split it into X and y sets.\n",
    "    :param data_file: str - train datado a research of your own\n",
    "    :return: pd.Series|list, pd.Series|list - X and y data series or lists\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_file)\n",
    "    total_bag_of_words = defaultdict(lambda: Counter())\n",
    "    for _, row in df.iterrows():\n",
    "        sentiment, text = row[\"sentiment\"], row[\"text\"]\n",
    "        bag_of_words = prepare_sentence(text)\n",
    "        for word, word_count in bag_of_words.items():\n",
    "            total_bag_of_words[sentiment][word] += word_count\n",
    "            \n",
    "    \n",
    "\n",
    "    return total_bag_of_words, df[\"sentiment\"]\n",
    "    \n",
    "# display(process_data(\"train.csv\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ntmhf9VA9u0d"
   },
   "source": [
    "*   If you need to implement some additional methods, feel free to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31634  - symbol values [\".\", \",\", \"(\", \")\", \":\", \"&\",\"-\", \"\\\"\",\"[\",\"]\", \"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30458 - replacing all punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23106 - using stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95OjORbi9zAW"
   },
   "source": [
    "### Implementation\n",
    "Implement each method of the BayesianClassifier \n",
    "created according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "rx2-IVxy-R99"
   },
   "outputs": [],
   "source": [
    "class BayesianClassifier:\n",
    "    \"\"\"\n",
    "    Implementation of Naive Bayes classification algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model: pd.DataFrame = None\n",
    "        self.lbl_properties: pd.DataFrame = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit Naive Bayes parameters according to train data X and y.\n",
    "        :param X: pd.DataFrame|list - train input/messages\n",
    "        :param y: pd.DataFrame|list - train output/labels\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        words_df = pd.DataFrame(X, )\n",
    "        words_df.fillna(0,inplace=True) # replace NaN with 0\n",
    "        words_df[\"word\"] = words_df.index\n",
    "        words_df[\"total\"] =  words_df[\"neutral\"] + words_df[\"negative\"] + words_df[\"positive\"]\n",
    "        words_df[\"total_count\"] =  words_df[\"total\"] / words_df[\"word\"].count()\n",
    "        for col in [\"neutral\",\"positive\", \"negative\"]:\n",
    "            words_df[col] = (words_df[col] + 1)/ (words_df[\"total\"] + words_df.iloc[0].count())\n",
    "            \n",
    "        words_df[\"total\"] =  words_df[\"total_count\"] \n",
    "        words_df = words_df.drop(\"total_count\", 1)\n",
    "       \n",
    "    \n",
    "        \n",
    "        label_series = y.value_counts()\n",
    "        label_total = label_series.sum()\n",
    "        \n",
    "#         labels_df = labels_df.append({\"neutral\":label_series[\"neutral\"] / label_total}, )\n",
    "        label_probabilities = { \n",
    "        \"neutral\" : label_series[\"neutral\"] / label_total,\n",
    "        \"positive\" : label_series[\"positive\"] / label_total,\n",
    "        \"negative\" : label_series[\"negative\"] / label_total\n",
    "        }\n",
    "        labels_df = pd.DataFrame(label_probabilities,columns=[\"label\", \"prob\"])\n",
    "        display(words_df)\n",
    "        display(labels_df)\n",
    "        self.model = words_df\n",
    "        self.lbl_properties = labels_df\n",
    "\n",
    "    def predict_prob(self, message, label):\n",
    "        \"\"\"\n",
    "        Calculate the probability that a given label can be assigned to a given message.\n",
    "        :param message: str - input message\n",
    "        :param label: str - label\n",
    "        :return: float - probability P(label|message)\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        lbl_props = self.lbl_properties\n",
    "        \n",
    "        multiplication = 1\n",
    "        for word, count in message.items():\n",
    "            word_info = model.loc[model['word'] == word]\n",
    "            if len(word_info) != 0:\n",
    "                word_info = word_info.iloc[0]\n",
    "                word_cond = word_info[label]\n",
    "                word_tot = word_info['total']\n",
    "            else:\n",
    "                # probability of word out of base\n",
    "                # doesn't affect comparison\n",
    "                word_cond = 1\n",
    "                word_tot = 1\n",
    "#                 word_cond = (0 + 1) / (lbl_props[lbl_props['label'] == label].iloc[0]['words_count'] + lbl_props[lbl_props['label'] == 'total'].iloc[0]['words_count'])\n",
    "#                 word_tot = 1 / lbl_props[lbl_props['label'] == 'total'].iloc[0]['words_count']\n",
    "            multiplication *= (word_cond / word_tot) ** count\n",
    "        \n",
    "        prob = lbl_props[lbl_props['label'] == label].iloc[0]['prob'] * multiplication\n",
    "        \n",
    "        return prob\n",
    "        \n",
    "\n",
    "    def predict(self, message):\n",
    "        \"\"\"\n",
    "        Predict label for a given message.\n",
    "        :param message: str - message\n",
    "        :return: str - label that is most likely to be truly assigned to a given message\n",
    "        \"\"\"\n",
    "        lbl_props = self.lbl_properties\n",
    "        lbls = lbl_props[lbl_props['label'] != 'total']['label']\n",
    "        \n",
    "        probs = {}\n",
    "        for lbl in lbls:\n",
    "            probs[lbl] = self.predict_prob(message, lbl)\n",
    "        probs = list(probs.items())\n",
    "        probs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return probs[0][0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the mean accuracy on the given test data and labels - the efficiency of a trained model.\n",
    "        :param X: pd.DataFrame|list - test data - messages\n",
    "        :param y: pd.DataFrame|list - test labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        cor_mes = 0\n",
    "        all_mes = len(X.index)\n",
    "        for idx, message in X.items():\n",
    "            pred = self.predict(message)\n",
    "            real = y.at[idx]\n",
    "            if pred == real:\n",
    "                cor_mes += 1\n",
    "\n",
    "        return cor_mes / all_mes\n",
    "\n",
    "# test\n",
    "    \n",
    "# classifier = BayesianClassifier()\n",
    "\n",
    "# classifier.fit(x, y)\n",
    "# print(classifier.predict(Counter({'difficult': 1, 'football': 1, 'chicccken': 1, 'Alps': 3})))\n",
    "# print(classifier.predict(Counter({'play': 1, 'chicccken': 1, 'Alps': 3})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW85An5p-sp3"
   },
   "source": [
    "### Testing\n",
    "*  Finally, after you are done with your classifier, test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "zo4TZVh4950E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>word</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.256198</td>\n",
       "      <td>accord</td>\n",
       "      <td>0.014517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gran</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>gran</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compani</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.030048</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>compani</td>\n",
       "      <td>0.104267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plan</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>plan</td>\n",
       "      <td>0.011361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>move</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>move</td>\n",
       "      <td>0.003408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130hectar</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>130hectar</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inhous</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>inhous</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opna</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>opna</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollex</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>pollex</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>tell</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7922 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            neutral  negative  positive       word     total\n",
       "accord     0.685950  0.033058  0.256198     accord  0.014517\n",
       "gran       0.250000  0.125000  0.250000       gran  0.000252\n",
       "compani    0.653846  0.030048  0.312500    compani  0.104267\n",
       "plan       0.656250  0.010417  0.302083       plan  0.011361\n",
       "move       0.545455  0.030303  0.333333       move  0.003408\n",
       "...             ...       ...       ...        ...       ...\n",
       "130hectar  0.142857  0.142857  0.285714  130hectar  0.000126\n",
       "inhous     0.142857  0.142857  0.285714     inhous  0.000126\n",
       "opna       0.142857  0.142857  0.285714       opna  0.000126\n",
       "pollex     0.142857  0.142857  0.285714     pollex  0.000126\n",
       "tell       0.142857  0.142857  0.285714       tell  0.000126\n",
       "\n",
       "[7922 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, prob]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-19a58c485862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-259-8a1eb34eb11c>\u001b[0m in \u001b[0;36mpredict_prob\u001b[0;34m(self, message, label)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mmultiplication\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword_cond\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mword_tot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbl_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmultiplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "train_X, train_y = process_data(\"train.csv\")\n",
    "test_X, test_y = process_data(\"test.csv\")\n",
    "\n",
    "classifier = BayesianClassifier()\n",
    "classifier.fit(train_X, train_y)\n",
    "classifier.predict_prob(test_X[0], test_y[0])\n",
    "\n",
    "print(\"model score: \", classifier.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkNytMyM-8n0"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Summarize your work by explaining in a few sentences the points listed below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpEbPLoyBTBA"
   },
   "source": [
    "* ### Describe the method implemented in general:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAivLQzK_Ksa"
   },
   "source": [
    "* ### List pros and cons of the method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW1pCL-ZBfUD"
   },
   "source": [
    "* ### Add a few sencences about your implementation of the classifier:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlIcMe8uBz-2"
   },
   "source": [
    "* ### Describe your results:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PS_Lab1_Template.ipynb",
   "provenance": [
    {
     "file_id": "1Av8y_HRDH36u-pA1zwEWZL9n8GdFvlrF",
     "timestamp": 1633697130382
    },
    {
     "file_id": "1aT_CtpODWI7otU6vibcvSxhQp3mXEaP3",
     "timestamp": 1633642142132
    }
   ]
  },
  "kernelspec": {
   "display_name": "PyCharm (lab1)",
   "language": "python",
   "name": "pycharm-62921896"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
